oodie.deltastreamer.ingestion.tablesToBeIngested=sales,customers
hoodie.deltastreamer.ingestion.sales.configFile=config/defailt_sales_config.properties
hoodie.deltastreamer.ingestion.customers.configFile=config/defailt_customer_config.properties


#Spark props
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.sql.catalog.spark_catalog=org.apache.spark.sql.hudi.catalog.HoodieCatalog
spark.sql.hive.convertMetastoreParquet=false

spark.hadoop.fs.s3a.access.key=admin
spark.hadoop.fs.s3a.secret.key=password
spark.hadoop.fs.s3a.endpoint=http://127.0.0.1:9000
spark.hadoop.fs.s3a.path.style.access=true
fs.s3a.signing-algorithm=S3SignerType


#Kafka props
bootstrap.servers=localhost:9092
auto.offset.reset=earliest
schema.registry.url=http://localhost:8081

hoodie.deltastreamer.source.kafka.value.deserializer.class=io.confluent.kafka.serializers.KafkaAvroDeserializer
hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.CustomKeyGenerator
hoodie.datasource.write.precombine.field=_event_origin_ts_ms
hoodie.onetable.formats.to.sync=DELTA,ICEBERG
hoodie.onetable.target.metadata.retention.hr=168
hoodie.metadata.index.async=true
hoodie.metadata.enable=true
hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.MultiPartKeysValueExtractor
hoodie.datasource.hive_sync.metastore.uris=thrift://localhost:9083
hoodie.datasource.hive_sync.mode=hms
hoodie.datasource.hive_sync.enable=true
hoodie.datasource.write.hive_style_partitioning=true
